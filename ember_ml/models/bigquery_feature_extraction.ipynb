{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigQuery Feature Extraction Example\n",
    "\n",
    "This notebook demonstrates how to use the `BigQueryFeatureExtractor` to extract features from Google BigQuery datasets for use with Ember ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ember_ml.nn import tensor\n",
    "from ember_ml import ops\n",
    "from ember_ml.nn.features.bigquery_feature_extractor import BigQueryFeatureExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize the Feature Extractor\n",
    "\n",
    "First, we need to initialize the BigQuery feature extractor with our project, dataset, and table information. If you have a service account key file, you can provide the path to it in the `credentials_path` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the feature extractor\n",
    "extractor = BigQueryFeatureExtractor(\n",
    "    project_id='your-project-id',\n",
    "    dataset_id='your-dataset-id',\n",
    "    table_id='your-table-id',\n",
    "    credentials_path='path/to/your/credentials.json'  # Optional\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Auto-detect Column Types\n",
    "\n",
    "We can automatically detect and categorize columns as numeric, categorical, or datetime based on their BigQuery data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-detect column types\n",
    "extractor.auto_detect_column_types()\n",
    "\n",
    "# Print the detected column types\n",
    "print(\"Numeric columns:\", extractor.numeric_columns)\n",
    "print(\"Categorical columns:\", extractor.categorical_columns)\n",
    "print(\"Datetime columns:\", extractor.datetime_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fetch Data\n",
    "\n",
    "Now we can fetch data from the BigQuery table. We can limit the number of rows, apply filters, and sort the data as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data with limit and filters\n",
    "data = extractor.fetch_data(\n",
    "    limit=1000,                  # Optional: Limit the number of rows\n",
    "    where_clause=\"column1 > 0\",  # Optional: Filter the data\n",
    "    order_by=\"column2 DESC\"      # Optional: Sort the data\n",
    ")\n",
    "\n",
    "# Display a sample of the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract Features\n",
    "\n",
    "Now we can extract features from the data. The feature extractor will process numeric, categorical, and datetime features and combine them into a single tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "features, feature_names = extractor.extract_features(\n",
    "    data=data,                   # Use the fetched data\n",
    "    handle_missing=True,         # Handle missing values\n",
    "    handle_outliers=True,        # Handle outliers\n",
    "    normalize=True,              # Normalize numeric features\n",
    "    create_samples=True,         # Create sample tables for visualization\n",
    "    capture_processing=True      # Capture processing steps for animation\n",
    ")\n",
    "\n",
    "# Print feature information\n",
    "print(f\"Features shape: {tensor.shape(features)}\")\n",
    "print(f\"Number of features: {len(feature_names)}\")\n",
    "print(f\"Feature names: {feature_names[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Sample Data\n",
    "\n",
    "We can visualize the sample data that was captured during feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display raw data sample\n",
    "pd.DataFrame(extractor.sample_tables['raw_data']['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display processed features sample\n",
    "pd.DataFrame(extractor.sample_tables['processed_features']['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Use the Features in a Model\n",
    "\n",
    "Now that we have extracted the features, we can use them in an Ember ML model. Here's a simple example using a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ember_ml.nn.modules import Sequential\n",
    "from ember_ml.nn.container import Linear\n",
    "from ember_ml.nn.modules.activations import ReLU, Sigmoid\n",
    "\n",
    "# Create a simple neural network\n",
    "model = Sequential([\n",
    "    Linear(tensor.shape(features)[1], 64),  # Input layer\n",
    "    ReLU(),\n",
    "    Linear(64, 32),                      # Hidden layer\n",
    "    ReLU(),\n",
    "    Linear(32, 1),                       # Output layer\n",
    "    Sigmoid()\n",
    "])\n",
    "\n",
    "# Forward pass\n",
    "output = model(features)\n",
    "print(f\"Output shape: {tensor.shape(output)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Execute Custom Queries\n",
    "\n",
    "You can also execute custom SQL queries directly on the BigQuery table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute a custom query\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "  column1,\n",
    "  AVG(column2) as avg_column2,\n",
    "  COUNT(*) as count\n",
    "FROM\n",
    "  `your-project-id.your-dataset-id.your-table-id`\n",
    "GROUP BY\n",
    "  column1\n",
    "ORDER BY\n",
    "  count DESC\n",
    "LIMIT\n",
    "  10\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "result = extractor.execute_query(query)\n",
    "\n",
    "# Display the result\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Working with Multiple Tables\n",
    "\n",
    "You can also create multiple feature extractors for different tables and combine their features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a second feature extractor\n",
    "extractor2 = BigQueryFeatureExtractor(\n",
    "    project_id='your-project-id',\n",
    "    dataset_id='your-dataset-id',\n",
    "    table_id='your-second-table-id',\n",
    "    credentials_path='path/to/your/credentials.json'  # Optional\n",
    ")\n",
    "\n",
    "# Auto-detect column types\n",
    "extractor2.auto_detect_column_types()\n",
    "\n",
    "# Fetch data\n",
    "data2 = extractor2.fetch_data(limit=1000)\n",
    "\n",
    "# Extract features\n",
    "features2, feature_names2 = extractor2.extract_features(data=data2)\n",
    "\n",
    "# Combine features\n",
    "all_features = ops.concatenate([features, features2], axis=1)\n",
    "all_feature_names = feature_names + feature_names2\n",
    "\n",
    "print(f\"Combined features shape: {tensor.shape(all_features)}\")\n",
    "print(f\"Total number of features: {len(all_feature_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Advanced Usage: Custom Feature Processing\n",
    "\n",
    "For more advanced feature processing, you can use the functions from the `bigquery` package directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ember_ml.nn.features.bigquery import (\n",
    "    process_numeric_features,\n",
    "    process_categorical_features,\n",
    "    normalize_robust,\n",
    "    hash_encode\n",
    ")\n",
    "\n",
    "# Custom numeric feature processing\n",
    "custom_numeric_tensor, custom_numeric_names = process_numeric_features(\n",
    "    df=data,\n",
    "    numeric_columns=['custom_column1', 'custom_column2'],\n",
    "    handle_missing=True,\n",
    "    handle_outliers=False,  # Skip outlier handling\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "# Custom hash encoding for a high-cardinality column\n",
    "hash_tensor, hash_names = hash_encode(\n",
    "    df=data,\n",
    "    column='high_cardinality_column',\n",
    "    n_components=32  # Use 32 hash components\n",
    ")\n",
    "\n",
    "# Combine custom features\n",
    "custom_features = ops.concatenate([custom_numeric_tensor, hash_tensor], axis=1)\n",
    "custom_feature_names = custom_numeric_names + hash_names\n",
    "\n",
    "print(f\"Custom features shape: {tensor.shape(custom_features)}\")\n",
    "print(f\"Number of custom features: {len(custom_feature_names)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

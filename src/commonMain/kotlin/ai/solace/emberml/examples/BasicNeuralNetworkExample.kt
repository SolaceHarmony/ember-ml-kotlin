package ai.solace.emberml.examples

import ai.solace.emberml.tensor.common.EmberTensor
import ai.solace.emberml.tensor.common.EmberShape
import ai.solace.emberml.tensor.common.EmberDType
import ai.solace.emberml.nn.layers.Dense
import ai.solace.emberml.nn.activations.ReLU
import ai.solace.emberml.nn.activations.Identity
import ai.solace.emberml.training.SGD
import ai.solace.emberml.training.MSELoss
import ai.solace.emberml.backend.BackendRegistry
import ai.solace.emberml.backend.OptimizedMegaTensorBackend

/**
 * Basic neural network example demonstrating the Ember ML Kotlin framework.
 * 
 * This example shows how to:
 * 1. Create tensors with the optimized backend
 * 2. Build a simple neural network with layers and activations
 * 3. Set up training with optimizers and loss functions
 * 4. Use broadcasting for tensor operations
 */
object BasicNeuralNetworkExample {
    
    /**
     * Demonstrates basic tensor operations with broadcasting.
     */
    suspend fun demonstrateTensorOperations() {
        println("=== Tensor Operations Demo ===")
        
        // Set up the optimized backend
        BackendRegistry.setBackend("mega")
        
        // Create some test tensors
        val tensor1 = EmberTensor(
            listOf(1.0f, 2.0f, 3.0f, 4.0f),
            EmberDType.FLOAT32
        )
        
        val tensor2 = EmberTensor(
            listOf(0.5f, 1.5f, 2.5f, 3.5f),
            EmberDType.FLOAT32
        )
        
        println("Tensor 1: shape ${tensor1.shape}, dtype ${tensor1.dtype}")
        println("Tensor 2: shape ${tensor2.shape}, dtype ${tensor2.dtype}")
        
        // Demonstrate element-wise operations (with broadcasting support)
        val sum = tensor1 + tensor2
        val product = tensor1 * tensor2
        val difference = tensor1 - tensor2
        
        println("Sum shape: ${sum.shape}")
        println("Product shape: ${product.shape}")
        println("Difference shape: ${difference.shape}")
        
        // Demonstrate matrix operations
        val matrix1 = EmberTensor(
            listOf(
                listOf(1.0f, 2.0f),
                listOf(3.0f, 4.0f)
            ),
            EmberDType.FLOAT32
        )
        
        val matrix2 = EmberTensor(
            listOf(
                listOf(5.0f, 6.0f),
                listOf(7.0f, 8.0f)
            ),
            EmberDType.FLOAT32
        )
        
        val matmulResult = matrix1.matmul(matrix2)
        println("Matrix multiplication result shape: ${matmulResult.shape}")
    }
    
    /**
     * Demonstrates a simple neural network setup.
     */
    suspend fun demonstrateNeuralNetwork() {
        println("\n=== Neural Network Demo ===")
        
        // Create layers
        val inputSize = 4
        val hiddenSize = 8
        val outputSize = 2
        
        val layer1 = Dense(inputSize, hiddenSize, useBias = true)
        val activation1 = ReLU()
        val layer2 = Dense(hiddenSize, outputSize, useBias = true)
        val activation2 = Identity()
        
        // Create optimizer and loss function
        val optimizer = SGD(learningRate = 0.01f, momentum = 0.9f)
        val lossFunction = MSELoss()
        
        // Create sample input
        val input = EmberTensor(
            listOf(1.0f, 2.0f, 3.0f, 4.0f),
            EmberDType.FLOAT32
        )
        
        val target = EmberTensor(
            listOf(0.5f, 1.5f),
            EmberDType.FLOAT32
        )
        
        println("Input shape: ${input.shape}")
        println("Target shape: ${target.shape}")
        
        // Forward pass
        val hidden = layer1.forward(input)
        val hiddenActivated = activation1.forward(hidden)
        val output = layer2.forward(hiddenActivated)
        val finalOutput = activation2.forward(output)
        
        println("Hidden layer output shape: ${hidden.shape}")
        println("Final output shape: ${finalOutput.shape}")
        
        // Compute loss
        val loss = lossFunction.forward(finalOutput, target)
        println("Loss shape: ${loss.shape}")
        
        // Demonstrate gradient computation
        val gradOutput = lossFunction.backward(finalOutput, target)
        println("Gradient shape: ${gradOutput.shape}")
        
        // Display layer parameters
        val layer1Params = layer1.parameters()
        val layer2Params = layer2.parameters()
        
        println("Layer 1 parameters: ${layer1Params.keys}")
        println("Layer 2 parameters: ${layer2Params.keys}")
        
        layer1Params["weight"]?.let { weight ->
            println("Layer 1 weight shape: ${weight.shape}")
        }
        
        layer2Params["weight"]?.let { weight ->
            println("Layer 2 weight shape: ${weight.shape}")
        }
    }
    
    /**
     * Demonstrates tensor slicing operations.
     */
    suspend fun demonstrateSlicing() {
        println("\n=== Tensor Slicing Demo ===")
        
        // Create a 2D tensor for slicing
        val tensor = EmberTensor(
            listOf(
                listOf(1.0f, 2.0f, 3.0f),
                listOf(4.0f, 5.0f, 6.0f),
                listOf(7.0f, 8.0f, 9.0f)
            ),
            EmberDType.FLOAT32
        )
        
        println("Original tensor shape: ${tensor.shape}")
        
        // The backend supports slicing operations, but we'd need to access them
        // through the backend interface. This demonstrates the architecture is in place.
        println("Slicing operations available through OptimizedMegaTensorBackend")
        println("- slice(tensor, ranges): Multi-dimensional slicing")
        println("- getElementAtIndex(tensor, indices): Single element access")
        println("- setElementAtIndex(tensor, indices, value): Single element update")
    }
    
    /**
     * Demonstrates bitwise operations capabilities.
     */
    suspend fun demonstrateBitwiseOperations() {
        println("\n=== Bitwise Operations Demo ===")
        
        // Create integer tensors for bitwise operations
        val tensor1 = EmberTensor(
            listOf(15, 7, 3, 1), // Binary: 1111, 0111, 0011, 0001
            EmberDType.INT32
        )
        
        val tensor2 = EmberTensor(
            listOf(12, 10, 6, 2), // Binary: 1100, 1010, 0110, 0010
            EmberDType.INT32
        )
        
        println("Tensor 1 shape: ${tensor1.shape}")
        println("Tensor 2 shape: ${tensor2.shape}")
        
        // Bitwise operations are available through the backend
        println("Bitwise operations available:")
        println("- bitwiseAnd, bitwiseOr, bitwiseXor, bitwiseNot")
        println("- leftShift, rightShift, rotateLeft, rotateRight")
        println("- countOnes, countZeros, getBit, setBit, toggleBit")
        println("- Wave operations: binaryWaveInterference, createDutyCycle, generateBlockySin")
    }
}

/**
 * Main function to run all examples.
 */
suspend fun runExamples() {
    BasicNeuralNetworkExample.demonstrateTensorOperations()
    BasicNeuralNetworkExample.demonstrateNeuralNetwork()
    BasicNeuralNetworkExample.demonstrateSlicing()
    BasicNeuralNetworkExample.demonstrateBitwiseOperations()
    
    println("\n=== Example Complete ===")
    println("All major Ember ML Kotlin components are functional!")
}